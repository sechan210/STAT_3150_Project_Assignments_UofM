---
title: 'STAT 3150: Assignment 3'
author: "Sechan, Kim"
date: "Due at 11:59 PM on October 24th, 2025"
output:
  pdf_document: default
  html_document:
    df_print: paged
header-includes: \linespread{1.3}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This assignment covers the modules on 

 - **Generating Random Variables** 
 - **Monte Carlo Integration**. 

The assignment contains **three problems** with multiple parts, worth a total of **30 marks**.

**Instructions**:

  - Rename the file `Assignment3.Rmd` as follows:
    + `LastnameFirstname_STAT3150-Assignment3.Rmd`
  - Change the author's name at the top (where you see `First, Last Name`).

  -  Your solutions must be typed using \LaTeX. One mark will be deducted each time an image is used to show a handwritten solution.
  
  - No extensions can be granted for this assignment (unless the student has special permission from Student Accessibility Services).
  
  - Assignments submitted after the deadline will receive a grade of zero and will not be accepted.
  
  - Solutions must be submitted electronically via UM Learn:
  
\begin{center}
\textbf{no later than 11:59PM CDT on Friday, October 24$^{\text{th}}$}
\end{center}
  
   - Please upload both the `Rmd` file and a PDF version of the output on UMLEARN: 
   
\begin{center}
Course Page > Assessment > Assignments > Assignment 3 > Add File. 
\end{center}

  - You are allowed to discuss the problems among yourselves, but your submission must reflect your original work. Note that your `R` code will be analysed for suspicious similarities.


  
------

\newpage

# Problem 1

Suppose \[f(x)=2x\]

where $0\le x \le 1$.

 a) **(2 marks)** Argue that $f(x)$ is a density function (i.e., show that it integrates to one, and that it is non-negative on its support).
$$
\int_{0}^{1} 2x \,dx = \left[ x^2 \right]_{0}^{1} = 1^2 - 0^2 = 1
\\
0\le x \le 1, so, f(x) = 2x\ge0
$$

 
 b) **(2 marks)** Find the CDF, $F(x)$ where $-\infty \le x \le \infty$.
$$
 F(x) = \int_{-\infty}^{x} f(t) \,dt
 \\
 For \ x \ < \ 0: F(x) = \int_{-\infty}^{x} 0dt \ = 0
 \\
 For \ 0 \le x \le 1: F(x) = \int_{0}^{x} 2t \,dt = \left[ t^2 \right]_{0}^{x} = x^2.
 \\
 For \ x \ge \ 1: F(x) = \int_{0}^{1} 2t \,dt = 1.
 \\
 So \ CDF \ is:
 \\
 F(x) = \begin{cases} 0 & \text{if } x < 0 \\ x^2 & \text{if } 0 \le x \le 1 \\ 1 & \text{if } x > 1 \end{cases}
$$
 
 c) **(2 marks)** Find the Quantile Function, $F^{-1}(p)$ where $0 \le x \le 1$.
$$
 Let \ F(x) \ = p, \ for \ p \in [0, 1].
 \\
 p = x^2
 \\
 x = \sqrt{p}
 \\
 So, \ the \ quantile \ function \ is \ F^{-1}(p) = \sqrt{p} \ for \ 0 \le p \le 1.
$$
 d) **(2 marks)** Explain and demonstrate how to use inverse transform sampling to generate random variates from this distribution using `R` code with `set.seed(3150)` and `n = 10000`. Then examine the histogram of the generated variates using `hist(., breaks = 50)`.
```{r}
set.seed(3150)
n <- 10000
u <- runif(n)
x <- sqrt(u)

hist(x, breaks = 50)
```

 e) **(2 marks)** Given a `Uniform(0,1)` proposal density, $g(x)$, find a value $C$ such that $C g(x)$ is an upper bound of $f(x)$ for all $x \in (0,1)$. Then, using the `R` code, generate 10000 random variates under $f(x)$ using the accept-reject method. Examine the histogram of the generated variates using `hist(., breaks = 50)`.
$$
 f(x) = 2x, \ so \ 2x\le C \cdot g(x) \ for \ all \ x \in (0,1).
\\
So \ C = 2
$$
 
 
```{r}
set.seed(3150)

n_required <- 10000
accepted_variates <- numeric(n_required)
count <- 0
C <- 2

while(count < n_required){
  y <- runif(1)
  u <- runif(1)
  
  if(u <= y){
    count <- count + 1
    accepted_variates[count] <- y
  }
}
hist(accepted_variates, breaks = 50)
```



\newpage

# Problem 2

For part (a), (b) and (c), consider the following integral:
\[
\theta = \int_0^{1}xe^{-\frac{1}{2}x^2}dx.
\]


  a. **(1 mark)** Use Monte Carlo integration to estimate $\theta$ by sampling from a $U(0, 1)$ distribution with `n=1000` and `set.seed(3150)`.
  
```{r}
set.seed(3150)
n <- 1000
x <- runif(n, 0,1)
h_x <- x * exp(-0.5*x^2)
theta <- mean(h_x)

print(paste("Estimate:", theta))

```
  
  b. **(3 marks)** Using `n=1000` and `set.seed(3150)`, find another estimate of $\theta$ by sampling from a standard normal distribution: $N(0,1)$.

  **Hint**: Think carefully about what $g(x)$ must be to make this integral equal to $E(g(X))$, with $X\sim N(0,1)$.
```{r}
set.seed(3150)
n <- 1000
x <- rnorm(n,0,1)

g_x <- ifelse(x > 0 & x < 1, sqrt(2*pi)*x,0)
theta_normal <- mean(g_x)
print(paste("Estimate of theta: ", theta_normal))

```
  
  c. **(2 marks)** For a fixed sample size `n=1000`, which of the two previous approaches has the smallest standard error?
```{r}
se_unif <- sd(h_x)/sqrt(n)
se_norm <- sd(g_x)/sqrt(n)

print(paste("Standard Error (Uniform):", se_unif))
print(paste("Standard Error (Normal):", se_norm))
print(paste("Uniform sampling has the smallest standard error."))


```

For part (d) and (e), consider the following equality:

\[
\pi = \int_0^1 \frac{4}{1 + x^2}dx.
\]

  d) **(2 marks)** Use Monte Carlo integration to estimate $\pi$ using `n = 1000` with `set.seed(3150)`. What is the standard error of this approach?
```{r}
set.seed(3150)
n <- 1000
x <- runif(n, 0, 1)
h_with_pi <- 4/(1+x^2)

pi <- mean(h_with_pi)
se <- sd(h_with_pi)/sqrt(n)
print(paste("Estimated pi:", pi))
print(paste("Standard Error:", se))

```

  e) **(2 marks)** Use antithetic variables to reduce the variance of your estimate from part (d). What is the standard error of this approach? Use `n = 1000` and `set.seed(3150)`.
```{r}
set.seed(3150)
n <- 1000
u <- runif(n/2, 0, 1)

h1 <- 4/(1+u^2)
h2 <- 4/(1+(1-u)^2)

final_h <- (h1+h2)/2
pi_h <- mean(final_h)
se_pi_h <- sd(final_h)/sqrt(n)

print(paste("Antithetic Variate Estimate of pi:", pi_h))
print(paste("Antithetic Variate Standard Error:", se_pi_h))
```

\newpage

# Problem 3

Suppose \[X_1,...,X_n \overset{\text{i.i.d.}}{\sim} exp(5).\] 

 a) **(2 marks)** Find the solution to the following integral using Monte Carlo integration:
\[
\psi= \int_0^5 5 e^{-5x}\, dx.
\]
```{r}
set.seed(3150)
n <- 1000
x <- runif(n, 0, 5)
value <- 5*exp(-5*x)
psi_estimate <- 5*mean(value)

print(paste("Estimate of psi:", psi_estimate))
```
 b) **(2 marks)** Using the 1000 observations from part (a), assess the convergence of cumulative mean as $n \rightarrow 1000$ with a trace plot. 
```{r}
X <- rexp(1000, rate = 5)
cumsum_mean <- cumsum(5 * exp(-5*X)) / (1:1000)
cumul_means <- cumsum(psi_estimate) / (1:n)
true <- 1-exp(-25)

plot(1:1000, cumsum_mean, type = 'l',
     main = "Convergence of Cumulative Mean",
     xlab = "n", ylab = "Cumulative Mean",
     ylim = c(0.8, 1.2))
abline(h = true, col = "red", lwd = 2)
```
 c) **(3 marks)** Using the inverse-transform method, generate 1000 antithetic variate for `exp(5)` distribution. Compare the standard error of antithetic variate with the standard error of 1000 observations from part (a). **Hint:** If $U\sim U(0,1)$ then $1-U \sim U(0,1)$. 
```{r}
set.seed(3150)
n <- 1000
m <- n/2

x_st <- rexp(n, rate = 5)
psi_st_samples <- (x_st <= 5)
se_st <- sd(psi_st_samples)/sqrt(n)

u <- runif(m)
x1 <- -log(1-u)/5
x2 <- -log(u)/5
paired <- (x1+x2)/2
mean_anti <- mean(paired)
se_anti <- sd(paired)/sqrt(m)

print(paste("Mean:", mean_anti))
print(paste("Standard Error:", se_anti))
```
 d) **(3 marks)** Use Monte Carlo integration to solve for \[\phi= \int_{0}^{5} 5 x^2  e^{-5x} dx\] and then use control variates with $h(x) = 5e^{-5x}$ to solve for the above integral. Compare the standard error of Monte Carlo estimator with control variate estimator.
```{r}
set.seed(3150)
n <- 1000
x <- rexp(n, rate = 5)
mu_c <- 1/5

phi_hat <- mean(5 * x^2 * exp(-5*x))

h_vals <- 5 * exp(-5*x)

mu <- 1

theta <- 5 * x^2 * exp(-5*x)
cov_th <- cov(theta, h_vals)
var_h <- var(h_vals)
lambda <- -cov_th/var_h

phi_cv <- mean(theta + lambda * (h_vals - mu))

se_phi <- sd(theta) / sqrt(n)
se_phi_cv <- sd(theta + lambda * (h_vals - mu)) / sqrt(n)

cat("Estimate (MC):", phi_hat, " SE:", se_phi, "\n")
cat("Estimate (Control Variate):", phi_cv, " SE:", se_phi_cv, "\n")
cat("Variance Reduction:", (1 - se_phi_cv^2/se_phi^2)*100, "%\n")
```

 
  